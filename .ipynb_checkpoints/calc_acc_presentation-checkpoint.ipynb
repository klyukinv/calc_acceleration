{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Аппаратное ускорение вычислений\n",
    "## Клюкин Валерий\n",
    "## БПИ173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Мотивация\n",
    "---\n",
    "Пример:\n",
    "<center><img src=\"pictures/motivation1.png\" width=\"400\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"pictures/motivation2.png\" width=\"400\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>\n",
    "Вывод: скорость произведения матриц важна для оптимизации работы нейросетей\n",
    "</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Матричное умножение\n",
    "---\n",
    "**Определение**: Произведением матриц $А$ размера $n \\times k$ и $B$ размера $k \\times m$ является матрица $C$ размера $n \\times m$ с элементами, равными:\n",
    "$$c_{ij} = \\sum \\limits_{s = 1}^{k}a_{is}b_{sj}, \\\\\n",
    "i = 1, \\dots, n; j=1, \\dots, m$$\n",
    "\n",
    "При размерности $m=k=n$ наивный алгоритм осуществляет $2n^3 - n^2 = \\mathcal{O}(n^3)$ операций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Матричное умножение\n",
    "---\n",
    "* Лежит в основе многих эффективных алгоритмов линейной алгебры. (*QR, LU, SVD - разложения*, *итеративные методы решения CЛАУ*)\n",
    "* Inference нейронной сети тоже представляет собой произведение матриц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Почему наивный алгоритм медленный?\n",
    "---\n",
    "1. Не использует преимущества архитектуры памяти компьютера.\n",
    "2. Не использует возможность параллелизации вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Иерархия памяти\n",
    "---\n",
    "<center><img src=\"pictures/Memory-Hierarchy.jpg\" width=\"700\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Быстрая память - дорогая\n",
    "* Медленной памяти гораздо больше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Идея:**\n",
    "Разбить матрицы на блоки. Для примера рассмотрим блочные матрицы $2 \\times 2$:\n",
    "$$A = \\begin{bmatrix}\n",
    "  A_{11} & A_{12}\\\\\n",
    "  A_{21} & A_{22}\\\\\n",
    "\\end{bmatrix}, B = \\begin{bmatrix}\n",
    "  B_{11} & B_{12}\\\\\n",
    "  B_{21} & B_{22}\\\\\n",
    "\\end{bmatrix}$$\n",
    "Тогда:\n",
    "$$A \\cdot B = \\begin{bmatrix}\n",
    "  A_{11} B_{11} + A_{12} B_{21} & A_{11} B_{12} + A_{12} B_{22}\\\\\n",
    "  A_{21} B_{11} + A_{22} B_{21} & A_{21} B_{12} + A_{22} B_{22}\\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Если $A_{11}, B_{11}$ и их произведение помещаются в кэш, то мы загружаем их в память только раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CPU vs GPU\n",
    "---\n",
    "<center><img src=\"pictures/bus_vs_plane.jpg\" title=\"cpu_vs_gpu\" width=500/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Отличия архитектур\n",
    "---\n",
    "<center><img src=\"pictures/architectures.png\" width=\"500\" align=\"center\"/></center>\n",
    "* ALU - Arithmetic logic unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Потребление энергии\n",
    "---\n",
    "<center><img src=\"https://ichef.bbci.co.uk/images/ic/720x405/p07p4w15.jpg\" title=\"greta\" width=200/></center>\n",
    "<center><img src=\"pictures/energy.png\" width=\"500\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Оптимизация задержки vs. Пропускная способность\n",
    "---\n",
    "<center><img src=\"pictures/threads.png\" width=\"700\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Устройство памяти GPU\n",
    "---\n",
    "<center><img src=\"pictures/gpu_memory.png\" width=\"700\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Чтение данных в GPU крайне медленное, так как $L1$-кэш очень маленький. Вычисления в $1000$ раз быстрее, чем чтение данных.\n",
    "<br>  \n",
    "$\\implies$ главным ботлнеком является чтение данных. Но как же тогда GPU ускоряет вычисления?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Произведение матриц на GPU\n",
    "---\n",
    "<center><img src=\"pictures/gpu_matrix1.png\" width=\"600\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Элементарный шаг:**\n",
    "* Чтение двух значений из матриц $M$ и $N$\n",
    "* Умножение значений и сложение с предыдущим значением $P$  \n",
    "\n",
    "**Вычислительная интенсивность:**\n",
    "* 2 операции на 2 чтения из глобальной памяти  \n",
    "\n",
    "**Если пропускная способность памяти - 300 GB/s:**\n",
    "* Tesla K40L 4.29 TFLOPS (float) - **всего лишь 2% от пиковой производительности**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Неэффективный доступ к элементам\n",
    "---\n",
    "<center><img src=\"pictures/gpu_threads1.png\" width=\"600\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Блочный доступ к памяти (Tiling)\n",
    "---\n",
    "<center><img src=\"pictures/gpu_threads2.png\" width=\"600\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Блочная схема умножения матриц\n",
    "---\n",
    "<center><img src=\"pictures/gpu_matrix2.png\" width=\"600\" align=\"center\"/><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GPU for Deep Learning\n",
    "---\n",
    "https://devblogs.nvidia.com/optimizing-gpu-performance-tensor-cores/  \n",
    "* Матрица может не делиться нацело между блоками (*tile quantization*)\n",
    "* Потоки могут не делиться нацело между мультипроцессорами (*wave quantization*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Tile quantization\n",
    "---\n",
    "<a><img src=\"https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/graphics/tile-quant.png\" title=\"tile\" width=800/></a>\n",
    "Tile quantization effect on (a) achieved flops throughput and (b) elapsed time, alongside (c) the number of tiles created. Measured with a function that forces the use of 256x128 tiles over the MxN output matrix. In practice, cuBLAS would select narrower tiles (for example, 64-wide) to reduce the quantization effect. Tesla V100-SXM3-32GB GPU, cuBLAS v10.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Wave quantization\n",
    "---\n",
    "<a><img src=\"https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/graphics/wave-quant-effects.png\" title=\"tile\" width=800/></a>\n",
    "The effects of wave quantization in terms of (a) achieved flops throughput and (b) elapsed time, as well as (c) the number of tiles created. Measured with a function that uses 256x128 tiles over the MxN output matrix. Note that the quantization effect occurs when the number of tiles passes a multiple of 80. Tesla V100-SXM3-32GB GPU, cuBLAS v10.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Как быть?\n",
    "---\n",
    "У видеокарт различаются: \n",
    "* размер L1 и L2 кэша\n",
    "* число ядер\n",
    "* число потоков\n",
    "<br>  \n",
    "Оптимальные схемы вычислений могут быть разными на разных видеокартах.\n",
    "<br>  \n",
    "Вручную задавать гиперпараметры для разных видеокарт? К счастью, этого делать не нужно!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Есть TensorRT!\n",
    "---\n",
    "* TensorRT ускоряет инференс нейронной сети\n",
    "<a><img src=\"https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/graphics/whatistrt2.png\" title=\"tensorrt\" width=800/></a>\n",
    "https://docs.nvidia.com/deeplearning/sdk/tensorrt-best-practices/index.html\n",
    "https://towardsdatascience.com/optimize-nvidia-gpu-performance-for-efficient-model-inference-f3e9874e9fdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Пример:**\n",
    "<a><img src=\"https://devblogs.nvidia.com/wp-content/uploads/2018/06/perf_correct-1024x576.png\" title=\"tensorrt_resnet\" width=900/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><b>Спасибо за внимание!</b><center/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
